#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ServiÃ§o LLM - Servidor para processamento de LLM
Este serviÃ§o fica em execuÃ§Ã£o e pode ser chamado pelo Laravel quando necessÃ¡rio.
"""

import os
import sys
import json
import time
from pathlib import Path
from dotenv import load_dotenv

# Adiciona o diretÃ³rio scripts ao path
sys.path.insert(0, str(Path(__file__).parent / 'scripts'))
sys.path.insert(0, str(Path(__file__).parent / 'utils'))

# Carrega variÃ¡veis de ambiente
load_dotenv()

def main():
    """FunÃ§Ã£o principal do serviÃ§o LLM."""
    print("ğŸš€ ServiÃ§o LLM iniciado...")
    print(f"ğŸ“ DiretÃ³rio de trabalho: {os.getcwd()}")
    print(f"ğŸ Python: {sys.version}")
    
    # Verifica se os mÃ³dulos necessÃ¡rios estÃ£o disponÃ­veis
    try:
        from llm_utils import format_input_data, generate_article_content
        print("âœ… MÃ³dulos LLM carregados com sucesso")
    except ImportError as e:
        print(f"âŒ Erro ao importar mÃ³dulos: {e}")
        sys.exit(1)
    
    # ServiÃ§o em execuÃ§Ã£o contÃ­nua (pode ser substituÃ­do por um servidor HTTP se necessÃ¡rio)
    print("â³ ServiÃ§o LLM em execuÃ§Ã£o...")
    print("ğŸ’¡ Este serviÃ§o pode ser chamado via scripts Python ou via Laravel")
    print("ğŸ“ Para testar, execute: python scripts/run_llm.py '{\"symbol\":\"PETR4\",...}'")
    
    # Loop simples para manter o serviÃ§o rodando
    # Em produÃ§Ã£o, vocÃª pode substituir isso por um servidor HTTP (Flask/FastAPI)
    try:
        while True:
            time.sleep(60)  # Aguarda 1 minuto antes de verificar novamente
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ServiÃ§o LLM encerrado")
        sys.exit(0)

if __name__ == "__main__":
    main()

